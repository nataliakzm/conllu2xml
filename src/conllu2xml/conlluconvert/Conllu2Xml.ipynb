{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202549,"status":"ok","timestamp":1674554360643,"user":{"displayName":"NATALIA KUZMINYKH","userId":"04917015866921161966"},"user_tz":-60},"id":"XWcLLnaI6gXy","outputId":"1215d3c7-6164-4cbb-f658-62d7cc58a3df"},"outputs":[{"name":"stdout","output_type":"stream","text":["185380 qitext elements created\n"]}],"source":["# Set the input and output directories\n","args = argparse.Namespace()\n","args.input_dir = '/content/Input'\n","args.output_dir = '/content/Output'\n","\n","# Iterate over all the .conllu files in the input directory\n","for filename in os.listdir(args.input_dir):\n","    if not filename.endswith('.conllu'):\n","        continue\n","    \n","    # Construct the full file path\n","    file_path = os.path.join(args.input_dir, filename)\n","\n","    # Open the file in read mode\n","    with open(file_path, 'r') as f:\n","        conllu_string = f.read()\n","        \n","        # Split the conllu string into a list of lines\n","        conllu_lines = conllu_string.split('\\n')\n","\n","        # Create the xml document and root element\n","        xmldoc = minidom.Document()\n","        root = xmldoc.createElement('trf')\n","        xmldoc.appendChild(root)\n","\n","        # Iterate over the list of lines and extract the values from each line\n","        conllu_parsed = []\n","        sentence = []\n","        id = 1\n","\n","        for line in conllu_lines:\n","            if line.startswith('#'):\n","                continue\n","            elif line == '':\n","                conllu_parsed.append(sentence)\n","                sentence = []\n","            else:\n","                columns = line.split('\\t')\n","                form = columns[1]\n","                upos = columns[3]\n","                feats = columns[5]\n","                token = {'form': form, 'upos': upos, 'feats': feats}\n","                sentence.append(token)            \n","\n","        # Iterate over the list of sentences and create the xml elements\n","        for i, sentence in enumerate(conllu_parsed):\n","\n","          # Create the qitext element and set the id attribute\n","          qitext = xmldoc.createElement('qitext')\n","          qitext.setAttribute('id', str(id))\n","\n","          # Create the plain element and add it to the qitext element\n","          plain = xmldoc.createElement('plain')\n","          plain_text = ' '.join([token['form'] for token in sentence])\n","          plain.appendChild(xmldoc.createTextNode(plain_text))\n","          qitext.appendChild(plain)\n","\n","          # Set the l attribute of the qitext element to the length of the plain text\n","          qitext.setAttribute('l', str(len(plain_text)))\n","\n","          # Parse the plain text into a list of sentences using the nlp function\n","          sentences = sent_tokenize(plain_text, language='french')\n","\n","          # Iterate over the list of tokens and create the qitoken elements\n","          start = 0\n","          sentence_counter = 0    \n","\n","          for j, token in enumerate(sentence):\n","            qitoken = xmldoc.createElement('qitoken')\n","            qitoken_text = f\"{token['form']} {token['upos']}:{token['feats']}\"\n","            qitoken_text = re.sub(r'&(?!amp;|lt;|gt;)', '&amp;', qitoken_text)\n","            qitoken_text = re.sub(r'<http', '&lt;http', qitoken_text)\n","            qitoken_text = re.sub(r'<', '&lt;', qitoken_text)\n","            qitoken_text = re.sub(r'>', '&gt;', qitoken_text)\n","            qitoken_text = re.sub(r'<(?=[a-zA-Z])', '&lt;', qitoken_text)\n","            qitoken_text = re.sub(r'>(?=[a-zA-Z])', '&gt;', qitoken_text)\n","            qitoken.appendChild(xmldoc.createTextNode(qitoken_text))\n","            qitoken.setAttribute('start', str(start))\n","            start += len(token['form']) + 1\n","            qitoken.setAttribute('end', str(start - 1))\n","            qitoken.setAttribute('sentence', str(sentence_counter + 1))\n","            qitext.appendChild(qitoken)\n","            \n","            \n","            # Increment the sentence counter if the current token is the last in a sentence\n","            if sentence_counter < len(sentences) and token['form'] == sentences[sentence_counter][-1]:\n","              sentence_counter += 1\n","\n","          root.appendChild(qitext)\n","\n","          # Increment the id counter\n","          id += 1\n","\n","        # Construct the output file path\n","        output_filename = filename.replace('.conllu', '.xml')\n","        output_path = os.path.join(args.output_dir, output_filename)\n","    \n","        # Write the xml document to the output file\n","        with open(output_path, 'w') as f:\n","          f.write(html.unescape(xmldoc.toprettyxml()))\n","\n","        # Print the number of xml elements created\n","        print(f'{len(root.getElementsByTagName(\"qitext\"))} qitext elements created')"]},{"cell_type":"markdown","metadata":{"id":"zJ4xgpvmkPHO"},"source":["# XML2TRF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19442,"status":"ok","timestamp":1674641656424,"user":{"displayName":"NATALIA KUZMINYKH","userId":"04917015866921161966"},"user_tz":-60},"id":"f-S9sjDxrJLb","outputId":"ddf14529-d778-4f9b-d75a-b8c96c0faea1"},"outputs":[{"name":"stdout","output_type":"stream","text":["TRF file created: /content/Output/de_hdt-ud_CLEAN.trf\n"]}],"source":["import os\n","from lxml import etree\n","\n","# Get the XML file name from the directory\n","xml_file = '/content/Output/de_hdt-ud_CLEAN.xml'\n","\n","# Get the TRF file name from the XML file name\n","trf_file = os.path.splitext(xml_file)[0] + \".trf\"\n","\n","# Open the XML file and ignore errors\n","parser = etree.XMLParser(recover=True)\n","tree = etree.parse(xml_file, parser=parser)\n","root = tree.getroot()\n","\n","# Open the TRF file\n","trf = open(trf_file, \"w\", encoding=\"utf-8\")\n","\n","# Write the TRF header\n","trf.write('<?xml version=\\'1.0\\' encoding=\\'UTF8\\' ?>\\n')\n","trf.write(\"<format>3.0</format>\\n\")\n","\n","# Initialize the ID counter\n","id_counter = 1\n","\n","# Get the qitext elements\n","qitext_elements = root.findall(\"./qitext\")\n","\n","# Iterate over the qitext elements\n","for qitext_element in qitext_elements:\n","    # Get the text for the qitext element\n","    text_element = qitext_element.find(\"plain\")\n","    if text_element is not None:\n","        text = text_element.text\n","    else:\n","        text = \"\"\n","    \n","    # Get the length of the text\n","    length = len(text) if text is not None else 0\n","    \n","    # Write the qitext element\n","    trf.write(\"<qitext id='{}' l='{}'>\\n\".format(id_counter, length))\n","    trf.write(\"<plain>{}</plain>\\n\".format(text))\n","    \n","    # Get the qitoken elements\n","    qitoken_elements = qitext_element.findall(\"qitoken\")\n","\n","    for token in qitoken_elements:\n","      start = token.attrib['start']\n","      end = token.attrib['end']\n","      #sentence = '1' # added the sentence variable\n","      trf.write(\"<qitoken start='{}' end='{}' sentence='1'>{} WORD OTHER</qitoken>\\n\".format(start, end, token.text))\n","      #trf.write(\"<qitoken start='{}' end='{}'>{} WORD</qitoken>\\n\".format(start, end, token.text))\n","\n","    # Write the end of the qitext element\n","    trf.write(\"</qitext>\\n\")\n","\n","    # Increment the ID counter\n","    id_counter += 1\n","\n","# Close the TRF file\n","trf.close()\n","\n","# Write the TRF file \n","print(\"TRF file created: \" + trf_file)"]},{"cell_type":"markdown","metadata":{"id":"SJj90MRRLGmy"},"source":["#Let's parse it"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xPjTyQnfLJLV"},"outputs":[],"source":["import os\n","import re\n","\n","# Specify the folder containing the TRF files\n","folder = \"/content/Output\"\n","\n","# Use the os.listdir() function to find all TRF files in the specified folder\n","for filename in os.listdir(folder):\n","    if filename.endswith(\".trf\"):\n","        filepath = os.path.join(folder, filename)\n","\n","        # Open the TRF file\n","        with open(filepath, \"r\") as f:\n","            trf_file = f.read()\n","\n","        # Use regular expressions to find all instances of \"qitoken\" tags and remove \":_\" from the 2nd argument\n","        trf_file = re.sub(r'qitoken(.*?) (\\w+):_', r'qitoken\\1 \\2', trf_file)\n","\n","        # Save the modified TRF file\n","        with open(filepath, \"w\") as f:\n","            f.write(trf_file)"]},{"cell_type":"markdown","metadata":{"id":"MA5rBmjHezRI"},"source":["# REDUCE THE SIZE\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":605,"status":"ok","timestamp":1675088217714,"user":{"displayName":"NATALIA KUZMINYKH","userId":"04917015866921161966"},"user_tz":-60},"id":"YvfHVm4pjRxK"},"outputs":[],"source":["def delete_lines(file_path, start_id):\n","    new_lines = []\n","    with open(file_path, \"r\") as file:\n","        lines = file.readlines()\n","        for line in lines:\n","            if \"qitext id\" in line and int(line.split(\"'\")[1]) < start_id:\n","                new_lines.append(line)\n","            elif \"qitext id\" in line and int(line.split(\"'\")[1]) >= start_id:\n","                break\n","            else:\n","                new_lines.append(line)\n","\n","    with open(file_path, \"w\") as file:\n","        file.writelines(new_lines)\n","\n","delete_lines(\"/content/es_ancora-ud.trf\",10001)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPbGKSxz51biIwwcGqsV8l9","collapsed_sections":["uBbaa5EqzPOU","zJ4xgpvmkPHO"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.2"},"vscode":{"interpreter":{"hash":"6b9fe29183b2ff999c4b08945b8e676d9a501eb862f9f355e2011ecda5ea8b66"}}},"nbformat":4,"nbformat_minor":0}
